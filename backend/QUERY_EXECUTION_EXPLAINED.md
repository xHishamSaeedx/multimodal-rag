# Query Execution Flow - Explained

This document explains what happens when a query is processed, based on the actual execution logs.

## Query: "what was the revenue generated by the tech sector in 2021"

### Phase 1: Request Initiation (Lines 74-76)

```
74| INFO: 127.0.0.1:60867 - "OPTIONS /api/v1/query HTTP/1.1" 200 OK
75| {"method": "POST", "path": "/api/v1/query", ... "event": "request_started"}
76| {"query_preview": "what was the revenue generated by the tech sector in 2021", ... "event": "query_processing_start"}
```

**What happened:**
- **OPTIONS request**: CORS preflight check (browser security)
- **POST request**: Actual query request received
- Query validated and processing started
- Query length: 57 characters
- Limit: 10 chunks requested
- Include sources: true

---

### Phase 2: Hybrid Retrieval - Embedding Generation (Line 77)

```
77| {"method": "async_await", "collections": ["text_chunks", "table_chunks", "image_chunks", "bm25"], 
    "event": "hybrid_retrieval_parallel_start"}
```

**What happened:**
- `HybridRetriever` started parallel retrieval
- Generated two embeddings:
  - **Text embedding** (768 dim) using `e5-base-v2` for text/table chunks
  - **Image embedding** (1024 dim) using CLIP for image chunks
- Prepared for 4 parallel searches:
  1. BM25 sparse search (Elasticsearch)
  2. Vector search in `text_chunks` (Qdrant)
  3. Vector search in `table_chunks` (Qdrant)
  4. Vector search in `image_chunks` (Qdrant)

**Duration**: ~0.355 seconds (embedding generation)

---

### Phase 3: Parallel Vector Searches (Lines 78-86)

```
78| HTTP Request: POST http://localhost:6333/collections/text_chunks/points/query "HTTP/1.1 200 OK"
79| HTTP Request: POST http://localhost:6333/collections/image_chunks/points/query "HTTP/1.1 200 OK"
80| HTTP Request: POST http://localhost:6333/collections/table_chunks/points/query "HTTP/1.1 200 OK"
81| {"results_count": 5, "event": "image_chunks_search_completed", "duration_seconds": 0.086}
82| {"collection": "image_chunks", "duration_seconds": 0.086, "results_count": 5}
83| {"results_count": 2, "event": "table_chunks_search_completed", "duration_seconds": 0.093}
84| {"collection": "table_chunks", "duration_seconds": 0.093, "results_count": 2}
85| {"results_count": 8, "event": "vector_search_completed", "duration_seconds": 0.118}
86| {"collection": "text_chunks", "duration_seconds": 0.118, "results_count": 8}
```

**What happened:**
All three vector searches executed **in parallel** (asyncio.gather):

1. **Image chunks search** (0.086s):
   - Found 5 image chunks related to "tech sector revenue 2021"
   - Fastest completion

2. **Table chunks search** (0.093s):
   - Found 2 table chunks (likely containing revenue data in tabular format)
   - Slightly slower than image search

3. **Text chunks search** (0.118s):
   - Found 8 text chunks with relevant information
   - Slowest of the three (but still very fast)

**Total vector search time**: ~0.118 seconds (longest of the three, since they ran in parallel)

---

### Phase 4: BM25 Sparse Search (Lines 87-89)

```
87| POST http://localhost:9200/rag_chunks/_search [status:200 duration:0.292s]
88| {"results_count": 20, "method": "BM25", "event": "bm25_search_completed"}
89| {"duration_seconds": 2.287, "results_count": 20, "text_chunks": 9, "table_chunks": 11, "image_chunks": 0}
```

**What happened:**
- BM25 keyword search in Elasticsearch
- Found 20 chunks matching keywords: "revenue", "tech", "sector", "2021"
- Breakdown: 9 text chunks, 11 table chunks, 0 image chunks
- **Duration**: 2.287 seconds (longest operation)

**Why slower?**
- Elasticsearch query processing
- Keyword matching across all indexed chunks
- Network latency to Elasticsearch

**Note**: BM25 ran in parallel with vector searches, but it's the bottleneck

---

### Phase 5: Result Merging & Scoring (Lines 90-91)

```
90| {"duration_seconds": 2.288, "bm25_duration_seconds": 2.287, "text_vector_duration_seconds": 0.118, 
    "table_vector_duration_seconds": 0.093, "image_vector_duration_seconds": 0.086, 
    "sequential_duration_seconds": 2.584, "time_saved_seconds": 0.296, "efficiency_percent": 11.5, 
    "total_chunks_found": 35, "text_chunks_found": 17, "table_chunks_found": 13, "image_chunks_found": 5}
91| {"results_count": 10, "text_chunks": 4, "table_chunks": 5, "image_chunks": 1, 
    "embedding_duration_seconds": 0.355, "retrieval_duration_seconds": 2.288, 
    "merge_duration_seconds": 0.0, "total_duration_seconds": 2.645}
```

**What happened:**

1. **Parallel execution saved time**:
   - Sequential would take: 2.584 seconds
   - Actual time: 2.288 seconds
   - **Time saved**: 0.296 seconds (11.5% efficiency gain)

2. **Total chunks found**: 35 chunks
   - 17 text chunks (from BM25 + vector)
   - 13 table chunks (from BM25 + vector)
   - 5 image chunks (from vector only)

3. **Merging & Deduplication**:
   - Merged results by `chunk_id` (removed duplicates)
   - Normalized scores (Min-Max per score type)
   - Combined scores with weighted average:
     - Sparse (BM25): 0.2 weight
     - Dense text: 0.3 weight
     - Dense table: 0.2 weight
     - Dense image: 0.3 weight

4. **Top-N Selection**:
   - Selected top 10 chunks based on combined scores
   - Final breakdown:
     - **4 text chunks**
     - **5 table chunks** (most relevant - likely contain revenue data)
     - **1 image chunk** (chart/graph showing revenue)

**Total retrieval time**: 2.645 seconds

---

### Phase 6: Answer Generation - Context Formatting (Lines 92-96)

```
92| {"chunks_retrieved": 10, "duration_seconds": 2.645, "event": "retrieval_completed"}
93| Initialized Supabase client for: https://sqnswbxqiplmknmmhmdi.supabase.co
94| Initialized Supabase image storage client
95| HTTP Request: POST https://sqnswbxqiplmknmmhmdi.supabase.co/storage/v1/object/sign/... "HTTP/2 200 OK"
96| {"text_chunks_count": 4, "table_chunks_count": 5, "message": "Both text and table chunks found - 
    deduplication may need verification", "event": "answer_generation_mixed_chunks"}
```

**What happened:**

1. **Supabase initialization**:
   - Connected to Supabase for image storage
   - Generated signed URL for the image chunk (valid for 1 hour)

2. **Context formatting**:
   - Processed 10 chunks:
     - **Text chunks**: Formatted with `[Document: filename, Chunk: N]` citations
     - **Table chunks**: Used `table_markdown` if available, else `chunk_text`
     - **Image chunk**: Generated signed URL and formatted with description

3. **Mixed chunks warning**:
   - System detected both text and table chunks
   - This is normal - tables are often extracted as both text and structured data
   - Deduplication handled by `chunk_id`

**Image processing**:
- Since vision mode is likely set to "captioning" (default), it used the stored caption
- If vision mode was "vision_llm", it would have downloaded the image and processed it with the query

---

### Phase 7: LLM Answer Generation (Lines 97-100)

```
97| HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
98| HTTP Request: POST https://sqnswbxqiplmknmmhmdi.supabase.co/storage/v1/object/sign/... "HTTP/2 200 OK"
99| {"answer_length": 319, "sources_count": 10, "total_tokens": 2482, "ttft_seconds": 1.022, 
    "model": "openai/gpt-oss-20b", "event": "answer_generation_completed"}
100| {"answer_length": 319, "sources_count": 10, "llm_duration_seconds": 2.232, "ttft_seconds": 1.022, 
     "model": "openai/gpt-oss-20b", "event": "answer_generation_completed"}
```

**What happened:**

1. **Groq API call**:
   - Model: `openai/gpt-oss-20b`
   - Sent system prompt + user prompt with formatted context
   - Context included: 4 text chunks, 5 table chunks, 1 image chunk

2. **Image URL generation** (line 98):
   - Generated another signed URL (likely for source citation)

3. **Response received**:
   - **Answer length**: 319 characters
   - **Time to First Token (TTFT)**: 1.022 seconds (time until first response token)
   - **Total LLM duration**: 2.232 seconds
   - **Token usage**: 2,482 tokens total
   - **Sources extracted**: 10 sources (all chunks used)

**Token breakdown** (estimated):
- Prompt tokens: ~1,500-2,000 (context + system prompt)
- Completion tokens: ~300-500 (answer)

---

### Phase 8: Response Completion (Lines 101-102)

```
101| {"method": "POST", "path": "/api/v1/query", "status_code": 200, "duration_seconds": 4.906, 
     "event": "request_completed"}
102| INFO: 127.0.0.1:60867 - "POST /api/v1/query HTTP/1.1" 200 OK
```

**What happened:**
- Request completed successfully
- **Total duration**: 4.906 seconds
- Status: 200 OK
- Response sent to client with:
  - Generated answer (319 chars)
  - 10 source citations
  - Token usage information
  - Retrieval statistics

---

## Performance Breakdown

| Phase | Duration | Percentage |
|-------|----------|------------|
| Embedding Generation | 0.355s | 7.2% |
| Parallel Retrieval | 2.288s | 46.6% |
|   - Vector searches | 0.118s | (parallel) |
|   - BM25 search | 2.287s | (parallel) |
| Context Formatting | ~0.4s | 8.1% |
| LLM Generation | 2.232s | 45.5% |
|   - TTFT | 1.022s | |
|   - Generation | 1.210s | |
| **Total** | **4.906s** | **100%** |

---

## Key Insights

1. **Parallel retrieval is effective**: Saved 0.296 seconds (11.5% efficiency)

2. **BM25 is the bottleneck**: 2.287s vs 0.118s for vector searches
   - Consider optimizing Elasticsearch queries or using faster hardware

3. **Table chunks are most relevant**: 5 out of 10 top chunks are tables
   - Revenue data is likely in tabular format
   - System correctly prioritized structured data

4. **Image chunk included**: 1 image chunk in top 10
   - Likely a chart/graph showing revenue data
   - Vision mode using stored caption (fast, no API calls)

5. **LLM generation is significant**: 45.5% of total time
   - TTFT: 1.022s (acceptable)
   - Total generation: 2.232s (reasonable for 319 char answer)

6. **Token usage**: 2,482 tokens
   - Context was substantial (multiple chunks)
   - Answer was concise (319 chars ≈ 80-100 tokens)

---

## What the User Received

The user got a response containing:
- **Answer**: 319-character answer about tech sector revenue in 2021
- **10 sources**: Citations to the chunks used
- **Metadata**: Model used, token counts, retrieval stats
- **Image URL**: Signed URL for the image chunk (if applicable)

The system successfully:
✅ Retrieved relevant chunks from multiple sources (text, tables, images)
✅ Merged and ranked results intelligently
✅ Generated a grounded answer with citations
✅ Provided source attribution for transparency

